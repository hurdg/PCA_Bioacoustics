{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amphibian Audio Data ETL Notebook\n",
    "\n",
    "### Overview:\n",
    "\n",
    "This notebook serves as a tool for the reformatting of amphibian audio data collected from 2019 through 2023.\n",
    "\n",
    "### Objective:\n",
    "\n",
    "The primary objective of this notebook is to reformat raw audio recordings into an analytically usable format and create a common file structurte. The audio recordings will be clipped into positive and negative samples, as defined by the annual summary reports provided through WIldTrax.\n",
    "\n",
    "### Contents:\n",
    "\n",
    "1. **Data Extraction**:\n",
    "   - Accessing and retrieving historical audio files from internal repositories.\n",
    "   - Reviewing the structure and organization of audio data collected during the specified timeframe.\n",
    "   \n",
    "2. **Data Preprocessing**:\n",
    "   - Conducting thorough cleaning and filtering of historical audio recordings.\n",
    "   - Standardizing audio formats and associated metadata to ensure consistency across datasets.\n",
    "   \n",
    "3. **Feature Extraction**:\n",
    "   - Extracting pertinent features from historical audio signals to aid in subsequent analysis.\n",
    "   - Calculating acoustic metrics essential for amphibian species identification and classification within the designated timeframe.\n",
    "   \n",
    "4. **Data Loading**:\n",
    "   - Efficiently loading processed audio data into structured databases or file systems.\n",
    "   - Establishing robust data pipelines for automated ETL processes, ensuring scalability and repeatability.\n",
    "\n",
    "### For future use :\n",
    "\n",
    "1. Execute each code cell sequentially by pressing Shift + Enter.\n",
    "2. Adhere to the provided instructions and comments within the code cells for guidance throughout the reformatting process.\n",
    "3. Tailor the code and parameters to suit the specific requirements and characteristics of the file structures of the data obtained after 2023.\n",
    "\n",
    "#### Environment Setup:\n",
    "\n",
    "Prior to commencing the reformatting process, ensure the presence of requisite Python libraries and dependencies. It is recommended to employ established tools such as Anaconda or virtual environments to manage the Python environment effectively.\n",
    "__________________________________________________________________________________________________________________________________________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#py v 3.12.3\n",
    "import os\n",
    "import glob\n",
    "import wave\n",
    "import csv\n",
    "\n",
    "#Not in base python\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify years for data collection\n",
    "year_list = ['2019', '2021', '2022', '2023']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create folders in parent directory (./analysis) to store wofr, weto, and negative audio samples (non-weto & non-wofr)\n",
    "\n",
    "parent = os.path.dirname(os.getcwd())\n",
    "\n",
    "wofr_path = os.path.join(parent, 'data', 'wofr')\n",
    "if not os.path.exists(wofr_path):\n",
    "    os.makedirs(wofr_path)\n",
    "\n",
    "weto_path = os.path.join(parent, 'data', 'weto')\n",
    "if not os.path.exists(weto_path):\n",
    "    os.makedirs(weto_path)\n",
    "\n",
    "negative_path = os.path.join(parent, 'data', 'negative')\n",
    "if not os.path.exists(negative_path):\n",
    "    os.makedirs(negative_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collect filepaths for annual data - preference shown for copies with naming convention that is consistent with WildTrax uploads\n",
    "\n",
    "wav_root = os.path.join('\\\\\\\\BAN-NAS-DATA', 'EI_Monitoring', 'Amphibian recordings')\n",
    "\n",
    "filepath_wav = [glob.glob(os.path.join(wav_root, '2019', 'Site*', '2019*', '*.wav')),\n",
    "                glob.glob(os.path.join(wav_root, '2021', '*for WildTrax', '2021*', '*.wav')),\n",
    "                glob.glob(os.path.join(wav_root, '2022', '*WildTrax copies', '*.wav')),\n",
    "                glob.glob(os.path.join(wav_root, '2023', '*.wav'))]\n",
    "\n",
    "\n",
    "#Create dictionary with years as the keys and the audio .wav filepaths as values\n",
    "\n",
    "wav_dict = dict(zip(year_list, filepath_wav))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collect metadata (main_report and recording_report CSVs from WIldTrax)\n",
    "\n",
    "metadata_root = os.path.join('\\\\\\\\Ban-files-01', 'groups', 'Resource Conservation', 'EI Monitoring', 'Amphibians', '_ARUs', 'Data and metadata', 'Data from WildTrax')\n",
    "filepath_metadata_tags = glob.glob(os.path.join(metadata_root, '*', '*main_report.csv'))\n",
    "filepath_metadata_index = glob.glob(os.path.join(metadata_root, '*', '*recording_report.csv'))\n",
    "\n",
    "\n",
    "#Create dictionary with years as keys and the 'main_report' .csv filepaths as values\n",
    "\n",
    "metadata_tag_dict = dict(zip(year_list, filepath_metadata_tags))\n",
    "\n",
    "\n",
    "#Create dictionary with years as keys and the 'recording_report' .csv filepaths as values\n",
    "\n",
    "metadata_index_dict = dict(zip(year_list, filepath_metadata_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dictionary of 'recording_id' and 'source_file_name' from main_report.csv and recording_report.csv, respectively.\n",
    "#This step is necessary to index tags from wildtrax back to the original wav files\n",
    "\n",
    "fileindex_dict = {}\n",
    "\n",
    "for year in year_list:\n",
    "    #fileindex_dict = {}\n",
    "    with open(metadata_index_dict[year],'r') as f: \n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            if row[7] not in fileindex_dict.keys(): #Prevent duplicate entries\n",
    "                fileindex_dict.update({row[7]: row[-2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a nested Function to accept wav filepath and cut it in accordance with specified start time and clip duration\n",
    "#Resulting file is deposited at outpath\n",
    "\n",
    "def snip_file(filepath, start, duration, outpathfile, min_snip_length = 2):\n",
    "        # file to extract the snippet from\n",
    "    with wave.open(filepath, \"rb\") as infile:\n",
    "        # get file data\n",
    "        nchannels = infile.getnchannels()\n",
    "        sampwidth = infile.getsampwidth()\n",
    "        framerate = infile.getframerate()\n",
    "        # extract data\n",
    "        # adjust so that the minimum extraction length is 2s\n",
    "        if duration > 2:\n",
    "            # set position in wave to start of segment\n",
    "            infile.setpos(int(start * framerate))\n",
    "            data = infile.readframes(int(duration * framerate))\n",
    "        else:\n",
    "            # Set position in wave to centre - (min_snip_length/2)\n",
    "            start_adj = start + (duration/2) - (min_snip_length/2)\n",
    "            if start_adj < 0:\n",
    "                start_adj = 0\n",
    "            infile.setpos(int((start_adj) * framerate))\n",
    "            data = infile.readframes(int(min_snip_length * framerate))\n",
    "\n",
    "    # write the extracted data to a new file\n",
    "    with wave.open(outpathfile, 'w') as outfile:\n",
    "        outfile.setnchannels(nchannels)\n",
    "        outfile.setsampwidth(sampwidth)\n",
    "        outfile.setframerate(framerate)\n",
    "        outfile.setnframes(int(len(data) / sampwidth))\n",
    "        outfile.writeframes(data)\n",
    "\n",
    "\n",
    "#Row-wise function to extract year of the row in question. ALong with start time of a proposed audio clip tag, and the duration. THe filepath is also identified.\n",
    "\n",
    "def snip_row(df_row, index, file_dict, outpath):\n",
    "    datetime = df_row['recording_date_time']\n",
    "    year = str(datetime.year)\n",
    "    start = df_row['detection_time']\n",
    "    duration = df_row['tag_duration']\n",
    "    recording_id = df_row['recording_id']\n",
    "    filename = index[recording_id]\n",
    "    matching_filepaths = [filepath for filepath in file_dict[year] if filename in filepath]\n",
    "    if len(matching_filepaths) >0:\n",
    "        filepath = matching_filepaths[0]\n",
    "        outpathfile = outpath + \"/\" + filename[:-4] + '_' + str(start) + '_' + str(duration) + '.wav'\n",
    "        snip_file(filepath = filepath, start = start, duration = duration, outpathfile = outpathfile)\n",
    "    else: \n",
    "        print(f\"No matching wave file for {filename}\")\n",
    "\n",
    "\n",
    "#Wrapper to accept csv filepath as input and process with above functions\n",
    "\n",
    "def snip_csv(wildtrax_mainreport_filepath, species_code, index, outpath, file_dict):\n",
    "    df = pd.read_csv(wildtrax_mainreport_filepath, parse_dates = ['recording_date_time'], dtype = {'recording_id': str})\n",
    "    species_types = ['weto', 'wofr']\n",
    "    if species_code.casefold() not in species_types:\n",
    "        raise ValueError(\"Invalid species_code. Expected one of: %s\" % species_types)\n",
    "    species_mask = df['species_code'].str.contains(species_code, case = False)\n",
    "    df[species_mask].apply(snip_row, index = index, outpath = outpath, file_dict = file_dict, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matcing wave file for BANFF-A-11_20190505_190000.wav\n",
      "No matcing wave file for BANFF-A-11_20190505_200000.wav\n",
      "No matcing wave file for BANFF-A-11_20190505_205345.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_220000.wav\n",
      "No matcing wave file for BANFF-A-11_20190505_190000.wav\n",
      "No matcing wave file for BANFF-A-11_20190505_190000.wav\n",
      "No matcing wave file for BANFF-A-11_20190505_190000.wav\n",
      "No matcing wave file for BANFF-A-11_20190505_190000.wav\n",
      "No matcing wave file for BANFF-A-11_20190505_190000.wav\n",
      "No matcing wave file for BANFF-A-11_20190505_200000.wav\n",
      "No matcing wave file for BANFF-A-11_20190505_200000.wav\n",
      "No matcing wave file for BANFF-A-11_20190505_200000.wav\n",
      "No matcing wave file for BANFF-A-11_20190505_200000.wav\n",
      "No matcing wave file for BANFF-A-11_20190505_200000.wav\n",
      "No matcing wave file for BANFF-A-11_20190505_200000.wav\n",
      "No matcing wave file for BANFF-A-11_20190505_205345.wav\n",
      "No matcing wave file for BANFF-A-11_20190505_205345.wav\n",
      "No matcing wave file for BANFF-A-11_20190505_205345.wav\n",
      "No matcing wave file for BANFF-A-11_20190505_205345.wav\n",
      "No matcing wave file for BANFF-A-11_20190505_205345.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_160000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_160000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_160000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_160000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_160000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_160000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_160000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_170000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_170000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_170000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_170000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_180000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_180000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_180000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_180000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_190000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_190000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_190000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_190000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_190000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_200000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_200000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_200000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_200000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_200000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_210000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_210000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_210000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_210000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_210000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_210000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_210000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_210000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_220000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_220000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_220000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_220000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_220000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_230000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_230000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_230000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_230000.wav\n",
      "No matcing wave file for BANFF-A-147_20190508_230000.wav\n",
      "No matcing wave file for BANFF-A-147_20190509_000000.wav\n",
      "No matcing wave file for BANFF-A-147_20190509_000000.wav\n",
      "No matcing wave file for BANFF-A-147_20190509_000000.wav\n",
      "No matcing wave file for BANFF-A-147_20190509_000000.wav\n",
      "No matcing wave file for BANFF-A-147_20190509_000000.wav\n",
      "No matcing wave file for BANFF-A-147_20190509_010000.wav\n",
      "No matcing wave file for BANFF-A-147_20190509_010000.wav\n",
      "No matcing wave file for BANFF-A-147_20190509_010000.wav\n",
      "No matcing wave file for BANFF-A-147_20190509_010000.wav\n",
      "No matcing wave file for BANFF-A-147_20190509_010000.wav\n",
      "No matcing wave file for A-11-E_20210506_010000.wav\n",
      "No matcing wave file for A-11-E_20210506_040000.wav\n",
      "No matcing wave file for A-11-E_20210506_160000.wav\n",
      "No matcing wave file for A-11-E_20210506_190000.wav\n",
      "No matcing wave file for A-11-E_20210506_210000.wav\n",
      "No matcing wave file for A-11-E_20210506_220000.wav\n",
      "No matcing wave file for A-17-E_20210507_010000.wav\n",
      "No matcing wave file for A-17-E_20210507_010000.wav\n",
      "No matcing wave file for A-17-E_20210507_040000.wav\n",
      "No matcing wave file for A-17-W_20210510_210000.wav\n",
      "No matcing wave file for A-60-W_20210508_040000.wav\n",
      "No matcing wave file for A-71-S_20210508_210000.wav\n",
      "No matcing wave file for A-71-S_20210508_220000.wav\n",
      "No matcing wave file for A-71-S_20210508_230000.wav\n",
      "No matcing wave file for A-11-E_20210506_010000.wav\n",
      "No matcing wave file for A-11-E_20210506_040000.wav\n",
      "No matcing wave file for A-11-E_20210506_070000.wav\n",
      "No matcing wave file for A-11-E_20210506_160000.wav\n",
      "No matcing wave file for A-11-E_20210506_190000.wav\n",
      "No matcing wave file for A-11-E_20210506_210000.wav\n",
      "No matcing wave file for A-11-E_20210506_220000.wav\n",
      "No matcing wave file for A-11-S_20210505_140000.wav\n",
      "No matcing wave file for A-11-S_20210505_150000.wav\n",
      "No matcing wave file for A-11-S_20210505_160000.wav\n",
      "No matcing wave file for A-120-E_20210504_200000.wav\n",
      "No matcing wave file for A-120-E_20210504_210000.wav\n",
      "No matcing wave file for A-120-E_20210504_220000.wav\n",
      "No matcing wave file for A-142-E_20210509_010000.wav\n",
      "No matcing wave file for A-142-E_20210509_040000.wav\n",
      "No matcing wave file for A-142-E_20210509_160000.wav\n",
      "No matcing wave file for A-142-E_20210509_190000.wav\n",
      "No matcing wave file for A-142-E_20210509_200000.wav\n",
      "No matcing wave file for A-142-E_20210509_220000.wav\n",
      "No matcing wave file for A-142-E_20210509_230000.wav\n",
      "No matcing wave file for A-158-N_20210507_010000.wav\n",
      "No matcing wave file for A-158-S_20210504_210000.wav\n",
      "No matcing wave file for A-17-E_20210507_040000.wav\n",
      "No matcing wave file for A-17-E_20210507_130000.wav\n",
      "No matcing wave file for A-17-E_20210507_160000.wav\n",
      "No matcing wave file for A-17-E_20210507_190000.wav\n",
      "No matcing wave file for A-17-E_20210507_200000.wav\n",
      "No matcing wave file for A-17-E_20210507_210000.wav\n",
      "No matcing wave file for A-17-E_20210507_220000.wav\n",
      "No matcing wave file for A-17-W_20210510_130000.wav\n",
      "No matcing wave file for A-17-W_20210510_160000.wav\n",
      "No matcing wave file for A-17-W_20210510_190000.wav\n",
      "No matcing wave file for A-17-W_20210510_200000.wav\n",
      "No matcing wave file for A-17-W_20210510_210000.wav\n",
      "No matcing wave file for A-17-W_20210510_220000.wav\n",
      "No matcing wave file for A-40_20210509_010000.wav\n",
      "No matcing wave file for A-47_20210506_190000.wav\n",
      "No matcing wave file for A-47_20210506_200000.wav\n",
      "No matcing wave file for A-47_20210506_210000.wav\n",
      "No matcing wave file for A-47_20210506_220000.wav\n",
      "No matcing wave file for A-60-E_20210507_010000.wav\n",
      "No matcing wave file for A-60-E_20210507_040000.wav\n",
      "No matcing wave file for A-60-E_20210507_160000.wav\n",
      "No matcing wave file for A-60-E_20210507_210000.wav\n",
      "No matcing wave file for A-60-W_20210508_010000.wav\n",
      "No matcing wave file for A-60-W_20210508_040000.wav\n",
      "No matcing wave file for A-60-W_20210508_220000.wav\n",
      "No matcing wave file for A-60-W_20210508_230000.wav\n",
      "No matcing wave file for A-71-S_20210508_010000.wav\n",
      "No matcing wave file for A-71-S_20210508_040000.wav\n",
      "No matcing wave file for A-71-S_20210508_220000.wav\n",
      "No matcing wave file for A-71-S_20210508_230000.wav\n",
      "No matcing wave file for A-74_20210505_010000.wav\n",
      "No matcing wave file for A-74_20210505_040000.wav\n",
      "No matcing wave file for A-74_20210505_130000.wav\n",
      "No matcing wave file for A-74_20210505_160000.wav\n",
      "No matcing wave file for A-74_20210505_190000.wav\n",
      "No matcing wave file for A-74_20210505_200000.wav\n",
      "No matcing wave file for A-74_20210505_210000.wav\n",
      "No matcing wave file for A-74_20210505_220000.wav\n",
      "No matcing wave file for A-9_20230512_225500.wav\n",
      "No matcing wave file for A-9_20230512_225500.wav\n",
      "No matcing wave file for A-9_20230512_225500.wav\n",
      "No matcing wave file for A-9_20230513_235500.wav\n",
      "No matcing wave file for A-9_20230513_235500.wav\n",
      "No matcing wave file for A-9_20230513_235500.wav\n",
      "No matcing wave file for A-9_20230515_225500.wav\n",
      "No matcing wave file for A-9_20230515_225500.wav\n",
      "No matcing wave file for A-9_20230515_225500.wav\n",
      "No matcing wave file for A-9_20230509_225500.wav\n",
      "No matcing wave file for A-9_20230509_225500.wav\n",
      "No matcing wave file for A-9_20230509_225500.wav\n",
      "No matcing wave file for A-9_20230509_225500.wav\n",
      "No matcing wave file for A-9_20230510_225500.wav\n",
      "No matcing wave file for A-9_20230510_225500.wav\n",
      "No matcing wave file for A-9_20230510_225500.wav\n",
      "No matcing wave file for A-9_20230512_225500.wav\n",
      "No matcing wave file for A-9_20230512_225500.wav\n",
      "No matcing wave file for A-9_20230512_225500.wav\n",
      "No matcing wave file for A-9_20230513_235500.wav\n",
      "No matcing wave file for A-9_20230513_235500.wav\n",
      "No matcing wave file for A-9_20230513_235500.wav\n",
      "No matcing wave file for A-9_20230515_225500.wav\n",
      "No matcing wave file for A-9_20230515_225500.wav\n",
      "No matcing wave file for A-9_20230515_225500.wav\n",
      "No matcing wave file for A-9_20230520_225500.wav\n",
      "No matcing wave file for A-9_20230520_225500.wav\n",
      "No matcing wave file for A-9_20230520_225500.wav\n"
     ]
    }
   ],
   "source": [
    "#Populate folder with snipped audio samples for weto and wofr\n",
    "\n",
    "for year in year_list:\n",
    "    snip_csv(metadata_tag_dict[year], species_code = 'WETO', index = fileindex_dict , outpath = weto_path, file_dict = wav_dict)\n",
    "    snip_csv(metadata_tag_dict[year], species_code = 'WOFR', index = fileindex_dict , outpath = wofr_path, file_dict = wav_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
