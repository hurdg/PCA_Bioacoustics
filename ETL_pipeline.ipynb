{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amphibian Audio Data ETL Notebook\n",
    "\n",
    "### Overview:\n",
    "\n",
    "This notebook serves as a tool for the reformatting of amphibian audio data collected from 2019 through 2023.\n",
    "\n",
    "### Objective:\n",
    "\n",
    "The primary objective of this notebook is to reformat raw audio recordings into an analytically usable format and create a common file structurte. The audio recordings will be clipped into positive and negative samples, as defined by the annual summary reports provided through WIldTrax.\n",
    "\n",
    "### Contents:\n",
    "\n",
    "1. **Data Extraction**:\n",
    "   - Accessing and retrieving historical audio files from internal repositories.\n",
    "   - Reviewing the structure and organization of audio data collected during the specified timeframe.\n",
    "   \n",
    "2. **Data Preprocessing**:\n",
    "   - Conducting thorough cleaning and filtering of historical audio recordings.\n",
    "   - Standardizing audio formats and associated metadata to ensure consistency across datasets.\n",
    "   \n",
    "3. **Feature Extraction**:\n",
    "   - Extracting pertinent features from historical audio signals to aid in subsequent analysis.\n",
    "   - Calculating acoustic metrics essential for amphibian species identification and classification within the designated timeframe.\n",
    "   \n",
    "4. **Data Loading**:\n",
    "   - Efficiently loading processed audio data into structured databases or file systems.\n",
    "   - Establishing robust data pipelines for automated ETL processes, ensuring scalability and repeatability.\n",
    "\n",
    "### For future use :\n",
    "\n",
    "1. Execute each code cell sequentially by pressing Shift + Enter.\n",
    "2. Adhere to the provided instructions and comments within the code cells for guidance throughout the reformatting process.\n",
    "3. Tailor the code and parameters to suit the specific requirements and characteristics of the file structures of the data obtained after 2023.\n",
    "\n",
    "#### Environment Setup:\n",
    "\n",
    "Prior to commencing the reformatting process, ensure the presence of requisite Python libraries and dependencies. It is recommended to employ established tools such as Anaconda or virtual environments to manage the Python environment effectively.\n",
    "__________________________________________________________________________________________________________________________________________________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#py v 3.12.3\n",
    "import os\n",
    "import glob\n",
    "import wave\n",
    "import csv\n",
    "import audioop\n",
    "\n",
    "#Not in base python\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify years for data collection\n",
    "year_list = ['2019', '2021', '2022', '2023']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create folders in parent directory (./analysis/) to store training data of wofr, weto, and negative audio samples (non-weto & non-wofr)\n",
    "\n",
    "train_parent = os.path.join(os.path.dirname(os.getcwd()), 'data')\n",
    "\n",
    "train_wofr_path = os.path.join(train_parent, 'wofr', 'train', 'positive')\n",
    "if not os.path.exists(train_wofr_path):\n",
    "    os.makedirs(train_wofr_path)\n",
    "\n",
    "train_weto_path = os.path.join(train_parent, 'weto', 'train', 'positive')\n",
    "if not os.path.exists(train_weto_path):\n",
    "    os.makedirs(train_weto_path)\n",
    "\n",
    "\n",
    "#Create folders in negative directory (./analysis/negative) to store none_wofr, none_weto, and all_negative audio samples\n",
    "\n",
    "train_weto_negative_path = os.path.join(train_parent, 'weto', 'train', 'negative')\n",
    "if not os.path.exists(train_weto_negative_path):\n",
    "    os.makedirs(train_weto_negative_path)\n",
    "\n",
    "train_wofr_negative_path = os.path.join(train_parent, 'wofr', 'train', 'negative')\n",
    "if not os.path.exists(train_wofr_negative_path):\n",
    "    os.makedirs(train_wofr_negative_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collect filepaths for annual data - preference shown for copies with naming convention that is consistent with WildTrax uploads\n",
    "\n",
    "wav_root = os.path.join('\\\\\\\\BAN-NAS-DATA', 'EI_Monitoring', 'Amphibian recordings')\n",
    "\n",
    "filepath_wav = [glob.glob(os.path.join(wav_root, '2019', 'Site*', '2019*', '*.wav')),\n",
    "                glob.glob(os.path.join(wav_root, '2021', '*for WildTrax', '2021*', '*.wav')),\n",
    "                glob.glob(os.path.join(wav_root, '2022', '*WildTrax copies', '*.wav')),\n",
    "                glob.glob(os.path.join(wav_root, '2023', '*.wav'))]\n",
    "\n",
    "\n",
    "#Create dictionary with years as the keys and the audio .wav filepaths as values\n",
    "\n",
    "wav_dict = dict(zip(year_list, filepath_wav))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collect metadata (main_report and recording_report CSVs from WIldTrax)\n",
    "\n",
    "metadata_root = os.path.join('\\\\\\\\Ban-files-01', 'groups', 'Resource Conservation', 'EI Monitoring', 'Amphibians', '_ARUs', 'Data and metadata', 'Data from WildTrax')\n",
    "filepath_metadata_tags = glob.glob(os.path.join(metadata_root, '*', '*main_report.csv'))\n",
    "filepath_metadata_index = glob.glob(os.path.join(metadata_root, '*', '*recording_report.csv'))\n",
    "\n",
    "\n",
    "#Create dictionary with years as keys and the 'main_report' .csv filepaths as values\n",
    "\n",
    "metadata_tag_dict = dict(zip(year_list, filepath_metadata_tags))\n",
    "\n",
    "\n",
    "#Create dictionary with years as keys and the 'recording_report' .csv filepaths as values\n",
    "\n",
    "metadata_index_dict = dict(zip(year_list, filepath_metadata_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dictionary of 'recording_id' and 'source_file_name' from main_report.csv and recording_report.csv, respectively.\n",
    "#This step is necessary to index tags from wildtrax back to the original wav files\n",
    "#NOTE: It appears that the source filenames listed in the wildtrax metadata (recording_report.csv) does not always align with existing wav files\n",
    "#       This appears to be true for all of 2019 data\n",
    "\n",
    "fileindex_dict = {}\n",
    "\n",
    "for year in year_list:\n",
    "    #fileindex_dict = {}\n",
    "    with open(metadata_index_dict[year],'r') as f: \n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            if row[7] not in fileindex_dict.keys(): #Prevent duplicate entries\n",
    "                fileindex_dict.update({row[7]: row[-2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dict of all possible tag codes and common names that have been used for amphibian recortdings in the wildtrax database\n",
    "\n",
    "tagname_tagcode_dict = {}\n",
    "\n",
    "for year in year_list:\n",
    "    tmp_dict = dict(zip(list(pd.read_csv(metadata_tag_dict[year], usecols = ['species_code'])['species_code']), \n",
    "                        list(pd.read_csv(metadata_tag_dict[year], usecols = ['species_common_name'])['species_common_name'])\n",
    "                        ))\n",
    "    tagname_tagcode_dict = {**tagname_tagcode_dict, **tmp_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a nested Function (x3) to accept wav filepath and cut it in accordance with specified start time and clip duration\n",
    "#Resulting file is deposited at outpath\n",
    "\n",
    "def snip_file(filepath, start, duration, outpathfile, min_snip_length = 2):\n",
    "        # file to extract the snippet from\n",
    "    \n",
    "    if duration != duration or start != start:\n",
    "        print(f\"{filepath} contains NAN for start and/or duration\")\n",
    "    else:\n",
    "        with wave.open(filepath, \"rb\") as infile:\n",
    "            # get file data\n",
    "            nchannels = infile.getnchannels()\n",
    "            sampwidth = infile.getsampwidth()\n",
    "            framerate = infile.getframerate()\n",
    "            # extract data\n",
    "            # adjust so that the minimum extraction length is 2s\n",
    "            if duration > 2:\n",
    "                # set position in wave to start of segment\n",
    "                infile.setpos(int(start * framerate))\n",
    "                data = infile.readframes(int(duration * framerate))\n",
    "            else:\n",
    "                # Set position in wave to centre - (min_snip_length/2)\n",
    "                start_adj = start + (duration/2) - (min_snip_length/2)\n",
    "                # Set start time floor at 0s\n",
    "                if start_adj < 0:\n",
    "                    start_adj = 0\n",
    "                infile.setpos(int((start_adj) * framerate))\n",
    "                data = infile.readframes(int(min_snip_length * framerate))\n",
    "\n",
    "        # write the extracted data to a new file\n",
    "        with wave.open(outpathfile, 'w') as outfile:\n",
    "            outfile.setnchannels(nchannels)\n",
    "            outfile.setsampwidth(sampwidth)\n",
    "            outfile.setframerate(framerate)\n",
    "            outfile.setnframes(int(len(data) / sampwidth))\n",
    "            outfile.writeframes(data)\n",
    "\n",
    "\n",
    "#Row-wise function to extract year of the row in question. ALong with start time of a proposed audio clip tag, and the duration. THe filepath is also identified.\n",
    "\n",
    "def snip_row(df_row, index, file_dict, outpath):\n",
    "    datetime = df_row['recording_date_time']\n",
    "    year = str(datetime.year)\n",
    "    start = df_row['detection_time']\n",
    "    duration = df_row['tag_duration']\n",
    "    recording_id = df_row['recording_id']\n",
    "    filename = index[recording_id]\n",
    "    matching_filepaths = [filepath for filepath in file_dict[year] if filename in filepath]\n",
    "    if len(matching_filepaths) >0:\n",
    "        filepath = matching_filepaths[0]\n",
    "        outpathfile = outpath + \"/\" + filename[:-4] + '_' + str(int(start)) + '_' + str(int(duration)) + '.wav'\n",
    "        snip_file(filepath = filepath, start = start, duration = duration, outpathfile = outpathfile)\n",
    "    else: \n",
    "        print(f\"No matching wave file for {filename}\")\n",
    "\n",
    "\n",
    "#Wrapper to accept csv filepath as input and process with above functions\n",
    "\n",
    "def snip_csv(wildtrax_mainreport_filepath, species_code, index, outpath, file_dict, regex= False):\n",
    "    df = pd.read_csv(wildtrax_mainreport_filepath, parse_dates = ['recording_date_time'], dtype = {'recording_id': str})\n",
    "    species_types = list(tagname_tagcode_dict.keys())\n",
    "    if species_code.casefold() not in [str.casefold(accepted_code) for accepted_code in species_types] and regex == False:\n",
    "        raise ValueError(f\"Invalid species_code. Expected one of: %s {species_types}\")\n",
    "    species_mask = df['species_code'].str.contains(species_code, case = False, regex = regex)\n",
    "    df[species_mask].apply(snip_row, index = index, outpath = outpath, file_dict = file_dict, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extract positive samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matching wave file for BANFF-A-11_20190505_190000.wav\n",
      "No matching wave file for BANFF-A-11_20190505_200000.wav\n",
      "No matching wave file for BANFF-A-11_20190505_205345.wav\n",
      "No matching wave file for BANFF-A-147_20190508_220000.wav\n",
      "No matching wave file for BANFF-A-11_20190505_190000.wav\n",
      "No matching wave file for BANFF-A-11_20190505_190000.wav\n",
      "No matching wave file for BANFF-A-11_20190505_190000.wav\n",
      "No matching wave file for BANFF-A-11_20190505_190000.wav\n",
      "No matching wave file for BANFF-A-11_20190505_190000.wav\n",
      "No matching wave file for BANFF-A-11_20190505_200000.wav\n",
      "No matching wave file for BANFF-A-11_20190505_200000.wav\n",
      "No matching wave file for BANFF-A-11_20190505_200000.wav\n",
      "No matching wave file for BANFF-A-11_20190505_200000.wav\n",
      "No matching wave file for BANFF-A-11_20190505_200000.wav\n",
      "No matching wave file for BANFF-A-11_20190505_200000.wav\n",
      "No matching wave file for BANFF-A-11_20190505_205345.wav\n",
      "No matching wave file for BANFF-A-11_20190505_205345.wav\n",
      "No matching wave file for BANFF-A-11_20190505_205345.wav\n",
      "No matching wave file for BANFF-A-11_20190505_205345.wav\n",
      "No matching wave file for BANFF-A-11_20190505_205345.wav\n",
      "No matching wave file for BANFF-A-147_20190508_160000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_160000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_160000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_160000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_160000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_160000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_160000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_170000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_170000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_170000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_170000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_200000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_200000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_200000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_200000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_200000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_210000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_210000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_210000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_210000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_210000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_210000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_210000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_210000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_220000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_220000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_220000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_220000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_220000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_230000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_230000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_230000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_230000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_230000.wav\n",
      "No matching wave file for BANFF-A-147_20190509_000000.wav\n",
      "No matching wave file for BANFF-A-147_20190509_000000.wav\n",
      "No matching wave file for BANFF-A-147_20190509_000000.wav\n",
      "No matching wave file for BANFF-A-147_20190509_000000.wav\n",
      "No matching wave file for BANFF-A-147_20190509_000000.wav\n",
      "No matching wave file for BANFF-A-147_20190509_010000.wav\n",
      "No matching wave file for BANFF-A-147_20190509_010000.wav\n",
      "No matching wave file for BANFF-A-147_20190509_010000.wav\n",
      "No matching wave file for BANFF-A-147_20190509_010000.wav\n",
      "No matching wave file for BANFF-A-147_20190509_010000.wav\n",
      "No matching wave file for A-11-E_20210506_010000.wav\n",
      "No matching wave file for A-11-E_20210506_040000.wav\n",
      "No matching wave file for A-11-E_20210506_160000.wav\n",
      "No matching wave file for A-11-E_20210506_190000.wav\n",
      "No matching wave file for A-11-E_20210506_210000.wav\n",
      "No matching wave file for A-11-E_20210506_220000.wav\n",
      "No matching wave file for A-17-E_20210507_010000.wav\n",
      "No matching wave file for A-17-E_20210507_010000.wav\n",
      "No matching wave file for A-17-E_20210507_040000.wav\n",
      "No matching wave file for A-17-W_20210510_210000.wav\n",
      "No matching wave file for A-60-W_20210508_040000.wav\n",
      "No matching wave file for A-71-S_20210508_210000.wav\n",
      "No matching wave file for A-71-S_20210508_220000.wav\n",
      "No matching wave file for A-71-S_20210508_230000.wav\n",
      "No matching wave file for A-11-E_20210506_010000.wav\n",
      "No matching wave file for A-11-E_20210506_040000.wav\n",
      "No matching wave file for A-11-E_20210506_070000.wav\n",
      "No matching wave file for A-11-E_20210506_160000.wav\n",
      "No matching wave file for A-11-E_20210506_190000.wav\n",
      "No matching wave file for A-11-E_20210506_210000.wav\n",
      "No matching wave file for A-11-E_20210506_220000.wav\n",
      "No matching wave file for A-11-S_20210505_140000.wav\n",
      "No matching wave file for A-11-S_20210505_150000.wav\n",
      "No matching wave file for A-11-S_20210505_160000.wav\n",
      "No matching wave file for A-120-E_20210504_200000.wav\n",
      "No matching wave file for A-120-E_20210504_210000.wav\n",
      "No matching wave file for A-120-E_20210504_220000.wav\n",
      "No matching wave file for A-142-E_20210509_010000.wav\n",
      "No matching wave file for A-142-E_20210509_040000.wav\n",
      "No matching wave file for A-142-E_20210509_160000.wav\n",
      "No matching wave file for A-142-E_20210509_190000.wav\n",
      "No matching wave file for A-142-E_20210509_200000.wav\n",
      "No matching wave file for A-142-E_20210509_220000.wav\n",
      "No matching wave file for A-142-E_20210509_230000.wav\n",
      "No matching wave file for A-158-N_20210507_010000.wav\n",
      "No matching wave file for A-158-S_20210504_210000.wav\n",
      "No matching wave file for A-17-E_20210507_040000.wav\n",
      "No matching wave file for A-17-E_20210507_130000.wav\n",
      "No matching wave file for A-17-E_20210507_160000.wav\n",
      "No matching wave file for A-17-E_20210507_190000.wav\n",
      "No matching wave file for A-17-E_20210507_200000.wav\n",
      "No matching wave file for A-17-E_20210507_210000.wav\n",
      "No matching wave file for A-17-E_20210507_220000.wav\n",
      "No matching wave file for A-17-W_20210510_130000.wav\n",
      "No matching wave file for A-17-W_20210510_160000.wav\n",
      "No matching wave file for A-17-W_20210510_190000.wav\n",
      "No matching wave file for A-17-W_20210510_200000.wav\n",
      "No matching wave file for A-17-W_20210510_210000.wav\n",
      "No matching wave file for A-17-W_20210510_220000.wav\n",
      "No matching wave file for A-40_20210509_010000.wav\n",
      "No matching wave file for A-47_20210506_190000.wav\n",
      "No matching wave file for A-47_20210506_200000.wav\n",
      "No matching wave file for A-47_20210506_210000.wav\n",
      "No matching wave file for A-47_20210506_220000.wav\n",
      "No matching wave file for A-60-E_20210507_010000.wav\n",
      "No matching wave file for A-60-E_20210507_040000.wav\n",
      "No matching wave file for A-60-E_20210507_160000.wav\n",
      "No matching wave file for A-60-E_20210507_210000.wav\n",
      "No matching wave file for A-60-W_20210508_010000.wav\n",
      "No matching wave file for A-60-W_20210508_040000.wav\n",
      "No matching wave file for A-60-W_20210508_220000.wav\n",
      "No matching wave file for A-60-W_20210508_230000.wav\n",
      "No matching wave file for A-71-S_20210508_010000.wav\n",
      "No matching wave file for A-71-S_20210508_040000.wav\n",
      "No matching wave file for A-71-S_20210508_220000.wav\n",
      "No matching wave file for A-71-S_20210508_230000.wav\n",
      "No matching wave file for A-74_20210505_010000.wav\n",
      "No matching wave file for A-74_20210505_040000.wav\n",
      "No matching wave file for A-74_20210505_130000.wav\n",
      "No matching wave file for A-74_20210505_160000.wav\n",
      "No matching wave file for A-74_20210505_190000.wav\n",
      "No matching wave file for A-74_20210505_200000.wav\n",
      "No matching wave file for A-74_20210505_210000.wav\n",
      "No matching wave file for A-74_20210505_220000.wav\n",
      "No matching wave file for A-9_20230512_225500.wav\n",
      "No matching wave file for A-9_20230512_225500.wav\n",
      "No matching wave file for A-9_20230512_225500.wav\n",
      "No matching wave file for A-9_20230513_235500.wav\n",
      "No matching wave file for A-9_20230513_235500.wav\n",
      "No matching wave file for A-9_20230513_235500.wav\n",
      "No matching wave file for A-9_20230515_225500.wav\n",
      "No matching wave file for A-9_20230515_225500.wav\n",
      "No matching wave file for A-9_20230515_225500.wav\n",
      "No matching wave file for A-9_20230509_225500.wav\n",
      "No matching wave file for A-9_20230509_225500.wav\n",
      "No matching wave file for A-9_20230509_225500.wav\n",
      "No matching wave file for A-9_20230509_225500.wav\n",
      "No matching wave file for A-9_20230510_225500.wav\n",
      "No matching wave file for A-9_20230510_225500.wav\n",
      "No matching wave file for A-9_20230510_225500.wav\n",
      "No matching wave file for A-9_20230512_225500.wav\n",
      "No matching wave file for A-9_20230512_225500.wav\n",
      "No matching wave file for A-9_20230512_225500.wav\n",
      "No matching wave file for A-9_20230513_235500.wav\n",
      "No matching wave file for A-9_20230513_235500.wav\n",
      "No matching wave file for A-9_20230513_235500.wav\n",
      "No matching wave file for A-9_20230515_225500.wav\n",
      "No matching wave file for A-9_20230515_225500.wav\n",
      "No matching wave file for A-9_20230515_225500.wav\n",
      "No matching wave file for A-9_20230520_225500.wav\n",
      "No matching wave file for A-9_20230520_225500.wav\n",
      "No matching wave file for A-9_20230520_225500.wav\n"
     ]
    }
   ],
   "source": [
    "#Populate folder with snipped audio samples for weto and wofr\n",
    "\n",
    "for year in year_list:\n",
    "    snip_csv(metadata_tag_dict[year], species_code = 'WETO', index = fileindex_dict , outpath = train_weto_path, file_dict = wav_dict)\n",
    "    snip_csv(metadata_tag_dict[year], species_code = 'WOFR', index = fileindex_dict , outpath = train_wofr_path, file_dict = wav_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CANG : Canada Goose\n",
      "COSN : Common Snipe\n",
      "CSFR : Columbia Spotted Frog\n",
      "HETF : Heavy traffic\n",
      "HETN : Heavy train\n",
      "HEWI : Heavy wind\n",
      "LIBA : Light Background Noise\n",
      "LIRA : Light rain\n",
      "LITF : Light traffic\n",
      "MOAI : Moderate aircraft\n",
      "MOBA : Moderate Background Noise\n",
      "MORA : Moderate rain\n",
      "MOTF : Moderate traffic\n",
      "MOTN : Moderate train\n",
      "MOWI : Moderate wind\n",
      "NONE : NONE\n",
      "NSWO : Northern Saw-whet Owl\n",
      "RESQ : Red Squirrel\n",
      "UNDU : Unidentified Duck\n",
      "UNFR : Unidentified Frog\n",
      "UNKN : Unidentified signal\n",
      "UNPA : Unidentified Passerine\n",
      "UNWO : Unidentified Woodpecker\n",
      "WETO : Western Toad\n",
      "WISN : Wilson's Snipe\n",
      "WOFR : Wood Frog\n"
     ]
    }
   ],
   "source": [
    "#View the tag codes and corresponding names\n",
    "\n",
    "for code in sorted(tagname_tagcode_dict): print(code, \":\", tagname_tagcode_dict[code]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extract negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to subset the main_report csvs from wildtrax to only include recordings that DO NOT contain the specified species code tag\n",
    "\n",
    "def get_neg_filepaths(neg_species:str, main_report_filepath:str, file_dict):\n",
    "    df = pd.read_csv(main_report_filepath, parse_dates = ['recording_date_time'], dtype = {'recording_id': str}) #read in csv\n",
    "    neg_mask = df[['recording_id', 'species_code']].groupby(['recording_id'])['species_code'].apply(lambda x: any(x == neg_species))\n",
    "    neg_dict = dict(zip(neg_mask.index, neg_mask.values)) #dict of key= recording_id and value= target species presence\n",
    "    neg_record_ids = [record_id for record_id, presence in neg_dict.items() if not presence] #extract record_ids of audio files that do not contain target species\n",
    "    non_null_mask = (df['species_code'] != 'NaN') & (df['species_code'] != 'NONE') & (df['recording_id'].isin(neg_record_ids)) #create maske\n",
    "    masked_df = df[non_null_mask] #apply mask\n",
    "    return(masked_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matching wave file for BANFF-A-11_20190505_170000.wav\n",
      "No matching wave file for BANFF-A-11_20190505_170000.wav\n",
      "No matching wave file for BANFF-A-11_20190505_170000.wav\n",
      "No matching wave file for BANFF-A-11_20190505_170000.wav\n",
      "No matching wave file for BANFF-A-11_20190505_170000.wav\n",
      "No matching wave file for BANFF-A-11_20190505_180000.wav\n",
      "No matching wave file for BANFF-A-11_20190505_180000.wav\n",
      "No matching wave file for BANFF-A-11_20190505_180000.wav\n",
      "No matching wave file for BANFF-A-11_20190505_180000.wav\n",
      "No matching wave file for BANFF-A-11_20190505_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_160000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_160000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_160000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_160000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_160000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_160000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_160000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_160000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_160000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_160000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_160000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_160000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_160000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_170000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_170000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_170000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_170000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_170000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_170000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_170000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_170000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_170000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_170000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_170000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_170000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_170000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_200000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_200000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_200000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_200000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_200000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_200000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_200000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_200000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_200000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_200000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_210000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_210000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_210000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_210000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_210000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_210000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_210000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_210000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_210000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_210000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_210000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_210000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_230000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_230000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_230000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_230000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_230000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_230000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_230000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_230000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_230000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_230000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_230000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_230000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_230000.wav\n",
      "No matching wave file for BANFF-A-147_20190508_230000.wav\n",
      "No matching wave file for BANFF-A-147_20190509_000000.wav\n",
      "No matching wave file for BANFF-A-147_20190509_000000.wav\n",
      "No matching wave file for BANFF-A-147_20190509_000000.wav\n",
      "No matching wave file for BANFF-A-147_20190509_000000.wav\n",
      "No matching wave file for BANFF-A-147_20190509_000000.wav\n",
      "No matching wave file for BANFF-A-147_20190509_000000.wav\n",
      "No matching wave file for BANFF-A-147_20190509_000000.wav\n",
      "No matching wave file for BANFF-A-147_20190509_000000.wav\n",
      "No matching wave file for BANFF-A-147_20190509_000000.wav\n",
      "No matching wave file for BANFF-A-147_20190509_000000.wav\n",
      "No matching wave file for BANFF-A-147_20190509_000000.wav\n",
      "No matching wave file for BANFF-A-147_20190509_000000.wav\n",
      "No matching wave file for BANFF-A-147_20190509_000000.wav\n",
      "No matching wave file for BANFF-A-147_20190509_010000.wav\n",
      "No matching wave file for BANFF-A-147_20190509_010000.wav\n",
      "No matching wave file for BANFF-A-147_20190509_010000.wav\n",
      "No matching wave file for BANFF-A-147_20190509_010000.wav\n",
      "No matching wave file for BANFF-A-147_20190509_010000.wav\n",
      "No matching wave file for BANFF-A-147_20190509_010000.wav\n",
      "No matching wave file for BANFF-A-147_20190509_010000.wav\n",
      "No matching wave file for BANFF-A-147_20190509_010000.wav\n",
      "No matching wave file for BANFF-A-147_20190509_010000.wav\n",
      "No matching wave file for BANFF-A-147_20190509_010000.wav\n",
      "No matching wave file for BANFF-A-147_20190509_010000.wav\n",
      "No matching wave file for BANFF-A-147_20190509_010000.wav\n",
      "No matching wave file for BANFF-A-147_20190509_010000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_160000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_160000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_160000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_160000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_160000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_160000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_160000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_160000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_160000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_170000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_170000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_170000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_170000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_170000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_170000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_170000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_170000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_200000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_200000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_200000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_200000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_200000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_200000.wav\n",
      "No matching wave file for BANFF-A-11_20190505_170000.wav\n",
      "No matching wave file for BANFF-A-11_20190505_170000.wav\n",
      "No matching wave file for BANFF-A-11_20190505_170000.wav\n",
      "No matching wave file for BANFF-A-11_20190505_170000.wav\n",
      "No matching wave file for BANFF-A-11_20190505_170000.wav\n",
      "No matching wave file for BANFF-A-11_20190505_180000.wav\n",
      "No matching wave file for BANFF-A-11_20190505_180000.wav\n",
      "No matching wave file for BANFF-A-11_20190505_180000.wav\n",
      "No matching wave file for BANFF-A-11_20190505_180000.wav\n",
      "No matching wave file for BANFF-A-11_20190505_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_160000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_160000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_160000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_160000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_160000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_160000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_160000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_160000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_160000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_170000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_170000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_170000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_170000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_170000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_170000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_170000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_170000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_180000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_190000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_200000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_200000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_200000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_200000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_200000.wav\n",
      "No matching wave file for BANFF-A-147_20190514_200000.wav\n",
      "No matching wave file for A-11-E_20210506_070000.wav\n",
      "No matching wave file for A-11-E_20210506_130000.wav\n",
      "No matching wave file for A-11-S_20210505_140000.wav\n",
      "No matching wave file for A-11-S_20210505_150000.wav\n",
      "No matching wave file for A-11-S_20210505_160000.wav\n",
      "No matching wave file for A-120-E_20210504_200000.wav\n",
      "No matching wave file for A-120-E_20210504_210000.wav\n",
      "No matching wave file for A-120-E_20210504_220000.wav\n",
      "No matching wave file for A-142-E_20210509_010000.wav\n",
      "No matching wave file for A-142-E_20210509_040000.wav\n",
      "No matching wave file for A-142-E_20210509_160000.wav\n",
      "No matching wave file for A-142-E_20210509_190000.wav\n",
      "No matching wave file for A-142-E_20210509_200000.wav\n",
      "No matching wave file for A-142-E_20210509_220000.wav\n",
      "No matching wave file for A-142-E_20210509_230000.wav\n",
      "No matching wave file for A-158-N_20210507_010000.wav\n",
      "No matching wave file for A-158-S_20210504_210000.wav\n",
      "No matching wave file for A-17-E_20210507_130000.wav\n",
      "No matching wave file for A-17-E_20210507_160000.wav\n",
      "No matching wave file for A-17-E_20210507_190000.wav\n",
      "No matching wave file for A-17-E_20210507_200000.wav\n",
      "No matching wave file for A-17-E_20210507_210000.wav\n",
      "No matching wave file for A-17-E_20210507_220000.wav\n",
      "No matching wave file for A-17-W_20210510_130000.wav\n",
      "No matching wave file for A-17-W_20210510_160000.wav\n",
      "No matching wave file for A-17-W_20210510_190000.wav\n",
      "No matching wave file for A-17-W_20210510_200000.wav\n",
      "No matching wave file for A-17-W_20210510_220000.wav\n",
      "No matching wave file for A-206-N_20210417_014000.wav\n",
      "No matching wave file for A-40_20210509_010000.wav\n",
      "No matching wave file for A-47_20210506_190000.wav\n",
      "No matching wave file for A-47_20210506_200000.wav\n",
      "No matching wave file for A-47_20210506_210000.wav\n",
      "No matching wave file for A-47_20210506_220000.wav\n",
      "No matching wave file for A-60-E_20210507_010000.wav\n",
      "No matching wave file for A-60-E_20210507_040000.wav\n",
      "No matching wave file for A-60-E_20210507_160000.wav\n",
      "No matching wave file for A-60-E_20210507_210000.wav\n",
      "No matching wave file for A-60-W_20210508_010000.wav\n",
      "No matching wave file for A-60-W_20210508_220000.wav\n",
      "No matching wave file for A-60-W_20210508_230000.wav\n",
      "No matching wave file for A-71-S_20210508_010000.wav\n",
      "No matching wave file for A-71-S_20210508_040000.wav\n",
      "No matching wave file for A-74_20210505_010000.wav\n",
      "No matching wave file for A-74_20210505_040000.wav\n",
      "No matching wave file for A-74_20210505_130000.wav\n",
      "No matching wave file for A-74_20210505_160000.wav\n",
      "No matching wave file for A-74_20210505_190000.wav\n",
      "No matching wave file for A-74_20210505_200000.wav\n",
      "No matching wave file for A-74_20210505_210000.wav\n",
      "No matching wave file for A-74_20210505_220000.wav\n",
      "No matching wave file for A-11-E_20210506_130000.wav\n",
      "No matching wave file for A-17-E_20210507_010000.wav\n",
      "No matching wave file for A-17-E_20210507_010000.wav\n",
      "No matching wave file for A-206-N_20210417_014000.wav\n",
      "No matching wave file for A-71-S_20210508_210000.wav\n",
      "No matching wave file for A-9_20230509_225500.wav\n",
      "No matching wave file for A-9_20230509_225500.wav\n",
      "No matching wave file for A-9_20230509_225500.wav\n",
      "No matching wave file for A-9_20230509_225500.wav\n",
      "No matching wave file for A-9_20230510_225500.wav\n",
      "No matching wave file for A-9_20230510_225500.wav\n",
      "No matching wave file for A-9_20230510_225500.wav\n",
      "No matching wave file for A-9_20230520_225500.wav\n",
      "No matching wave file for A-9_20230520_225500.wav\n",
      "No matching wave file for A-9_20230520_225500.wav\n"
     ]
    }
   ],
   "source": [
    "#Identify and extract audio clips that DO NOT contain the specified target species, but DO contain non-target species/sounds (e.g. train)\n",
    "#populate the negative directories\n",
    "\n",
    "for year in year_list:\n",
    "    #Apply function to create df that does not contain target species, but does contain tagged vocalizations/sounds\n",
    "    weto_masked_df = get_neg_filepaths(neg_species ='WETO', main_report_filepath = metadata_tag_dict[year], file_dict = wav_dict[year])\n",
    "    wofr_masked_df = get_neg_filepaths(neg_species ='WOFR', main_report_filepath = metadata_tag_dict[year], file_dict = wav_dict[year])\n",
    "\n",
    "    #apply snip_row function (created above) to populate negative folders\n",
    "    weto_masked_df.apply(snip_row, index = fileindex_dict, outpath = train_weto_negative_path, file_dict = wav_dict, axis = 1)\n",
    "    wofr_masked_df.apply(snip_row, index = fileindex_dict, outpath = train_wofr_negative_path, file_dict = wav_dict, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partition the audio files into a training and testing set\n",
    "Split the audio files randomly (using np.random) such that 10% of all data types (weto/wofr; pos/neg) are witheld for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create folders in parent directory (./analysis/) to store wofr and weto testing  samples (non-weto & non-wofr)\n",
    "\n",
    "test_parent = os.path.join(os.path.dirname(os.getcwd()), 'data')\n",
    "\n",
    "test_wofr_path = os.path.join(test_parent, 'wofr', 'test', 'positive')\n",
    "if not os.path.exists(test_wofr_path):\n",
    "    os.makedirs(test_wofr_path)\n",
    "\n",
    "test_weto_path = os.path.join(test_parent, 'weto', 'test', 'positive')\n",
    "if not os.path.exists(test_weto_path):\n",
    "    os.makedirs(test_weto_path)\n",
    "\n",
    "\n",
    "#Create folders in negative directory (./analysis/negative) to store none_wofr and none_weto testing audio samples\n",
    "\n",
    "test_weto_negative_path = os.path.join(test_parent, 'weto', 'test', 'negative')\n",
    "if not os.path.exists(test_weto_negative_path):\n",
    "    os.makedirs(test_weto_negative_path)\n",
    "\n",
    "test_wofr_negative_path = os.path.join(test_parent, 'wofr', 'test', 'negative')\n",
    "if not os.path.exists(test_wofr_negative_path):\n",
    "    os.makedirs(test_wofr_negative_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313 0\n",
      "779 0\n",
      "1038 0\n",
      "64 0\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir(train_weto_path)), len(os.listdir(test_weto_path)))\n",
    "print(len(os.listdir(train_weto_negative_path)), len(os.listdir(test_weto_negative_path)))\n",
    "print(len(os.listdir(train_wofr_path)), len(os.listdir(test_wofr_path)))\n",
    "print(len(os.listdir(train_wofr_negative_path)), len(os.listdir(test_wofr_negative_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_directories = {\"weto_pos\":[train_weto_path, test_weto_path], \n",
    "                        \"weto_neg\":[train_weto_negative_path, test_weto_negative_path], \n",
    "                        \"wofr_pos\":[train_wofr_path, test_wofr_path], \n",
    "                        \"wofr_neg\":[train_wofr_negative_path, test_wofr_negative_path]}\n",
    "\n",
    "np.random.seed(42) #Set seed for reproduceability\n",
    "\n",
    "for key, value in training_directories.items():\n",
    "    train_dir = value[0]\n",
    "    test_dir = value[1]\n",
    "    if len(os.listdir(test_dir)) ==0:\n",
    "        files = glob.glob(os.path.join(train_dir, '*.wav'))\n",
    "        random_files = np.random.choice(a = files,                  \n",
    "                                        size =  int(len(files)*.1), \n",
    "                                        replace = False)            #Sample without replacement\n",
    "        for filepath in random_files:\n",
    "            filename = os.path.relpath(filepath, train_dir)\n",
    "\n",
    "            test_filepath = os.path.join(test_dir, filename)\n",
    "            os.rename(filepath, test_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282 31\n",
      "702 77\n",
      "935 103\n",
      "58 6\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir(train_weto_path)), len(os.listdir(test_weto_path)))\n",
    "print(len(os.listdir(train_weto_negative_path)), len(os.listdir(test_weto_negative_path)))\n",
    "print(len(os.listdir(train_wofr_path)), len(os.listdir(test_wofr_path)))\n",
    "print(len(os.listdir(train_wofr_negative_path)), len(os.listdir(test_wofr_negative_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Audio clips of three seconds will be used to trian the model\n",
    "#For extracted audio that is greater than 3s, split it into sequential clips of 3s.\n",
    "\n",
    "parent = os.path.join(os.path.dirname(os.getcwd()), 'data')\n",
    "\n",
    "train_weto_path = os.path.join(parent, 'weto', 'train', 'positive')\n",
    "train_wofr_path = os.path.join(parent, 'wofr', 'train', 'positive')\n",
    "\n",
    "train_no_weto_path = os.path.join(parent, 'weto', 'train', 'negative')\n",
    "train_no_wofr_path = os.path.join(parent, 'wofr', 'train', 'negative')\n",
    "\n",
    "for dir in [train_weto_path, train_wofr_path, train_no_weto_path, train_no_wofr_path]:\n",
    "    for filename in os.listdir(dir):\n",
    "        filepath = os.path.join(dir, filename)\n",
    "        with wave.open(filepath, \"rb\") as infile:\n",
    "            framerate = infile.getframerate()\n",
    "            nchannels = infile.getnchannels()\n",
    "            sampwidth = infile.getsampwidth()\n",
    "            frames = infile.getnframes()\n",
    "            n_3s_segments = round(frames/(framerate*3)) # round down to number of full 3s segments within target audio clip\n",
    "            start = 0\n",
    "            for i in range(0, n_3s_segments):\n",
    "                infile.setpos(1+int(start * framerate))\n",
    "                data = infile.readframes(int(3 * framerate))\n",
    "                outpathfile = os.path.join(dir, str.split(filename, \".wav\")[0] + \"_\" + str(start) + \"-\" +str(start+3) + \".wav\")\n",
    "                \n",
    "                #Resample to 16k hz\n",
    "                #Maintains data integrity and improves computation efficiency\n",
    "                try:\n",
    "                    data_16k = audioop.ratecv(data,       #data\n",
    "                                            sampwidth,    #width\n",
    "                                            nchannels,    #nchannels\n",
    "                                            framerate,    #inrate\n",
    "                                            16000,        #outrate\n",
    "                                            None)         #state\n",
    "                except:\n",
    "                    print(f\"Failed to downsample {filepath}\")\n",
    "                with wave.open(outpathfile, 'w') as outfile:\n",
    "                    outfile.setnchannels(nchannels)\n",
    "                    outfile.setsampwidth(sampwidth)\n",
    "                    outfile.setframerate(16000)\n",
    "                    outfile.setnframes(int(len(data_16k[0]) / sampwidth))\n",
    "                    outfile.writeframes(data_16k[0])    \n",
    "                start += 3\n",
    "        try:\n",
    "            os.remove(filepath)\n",
    "        except:\n",
    "            print(f\"Could not remove {filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Switch to conda environment (for TensorFLow)\n",
    "#Signal processing with Tensorflow rather than librosa to ensure consistency with incoming data during model implementation\n",
    "\n",
    "#py v 3.9.19\n",
    "import os\n",
    "import wave\n",
    "\n",
    "#Not in base python\n",
    "import tensorflow as tf \n",
    "import tensorflow_io as tfio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'display'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[116], line 17\u001b[0m\n\u001b[0;32m     13\u001b[0m spectrogram \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mabs(spectrogram)\n\u001b[0;32m     14\u001b[0m spectrogram \u001b[38;5;241m=\u001b[39m spectrogram[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, tf\u001b[38;5;241m.\u001b[39mnewaxis]\n\u001b[1;32m---> 17\u001b[0m \u001b[43mdisplay\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisplay\u001b[49m(display\u001b[38;5;241m.\u001b[39mAudio(file_contents, rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16000\u001b[39m))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'display'"
     ]
    }
   ],
   "source": [
    "file_contents = tf.io.read_file(filename)\n",
    "wav, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1)\n",
    "wav = tfio.audio.resample(\n",
    "                            tf.squeeze(wav, axis=-1), #remove trailing axis\n",
    "                            rate_in=tf.cast(sample_rate, dtype=tf.int64), #specify input sampling rate as int64\n",
    "                            rate_out=16000 #specify desired output sampling rate\n",
    "                          )\n",
    "\n",
    "wav = wav[:48000]\n",
    "zero_padding = tf.zeros([48000] - tf.shape(wav), dtype=tf.float32)\n",
    "wav = tf.concat([zero_padding, wav],0)\n",
    "spectrogram = tf.signal.stft(wav, frame_length=255, frame_step=64)\n",
    "spectrogram = tf.abs(spectrogram)\n",
    "spectrogram = spectrogram[..., tf.newaxis]\n",
    "\n",
    "\n",
    "display.display(display.Audio(file_contents, rate=16000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
