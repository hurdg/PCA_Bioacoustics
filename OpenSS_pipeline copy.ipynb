{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\amphib_pt\\lib\\site-packages\\opensoundscape\\ml\\cnn.py:18: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "# the cnn module provides classes for training/predicting with various types of CNNs\n",
    "from opensoundscape import AudioFileDataset, SpectrogramPreprocessor\n",
    "from opensoundscape.ml.utils import collate_audio_samples_to_tensors\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#other utilities and packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from tqdm.auto import tqdm\n",
    "import wandb\n",
    "\n",
    "#non-tutorial\n",
    "import os\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created train_df (len 1143) and valid_df (len 202)\n",
      "There are 500 positive samples in train_df\n",
      "There are 643 negative samples in train_df\n"
     ]
    }
   ],
   "source": [
    "#Create metadata CSV for OpenSoundScape module\n",
    "\n",
    "data_dir = os.path.join(os.path.dirname(os.getcwd()), 'data')\n",
    "\n",
    "filepath_presence_dict = {\"filepath\":[], \"presence\":[]}\n",
    "\n",
    "weto_train_dir = os.path.join(data_dir, 'weto', 'train')\n",
    "for set_key in ['positive', 'negative']:\n",
    "    set_dir = os.path.join(weto_train_dir, set_key)\n",
    "    filenames = os.listdir(set_dir)\n",
    "    filepath_list = filepath_presence_dict[\"filepath\"]\n",
    "    presence_list = filepath_presence_dict[\"presence\"]\n",
    "    for name in filenames:\n",
    "        filepath = os.path.join(set_dir, name)\n",
    "        filepath_list.append(filepath)\n",
    "    filepath_presence_dict.update({'filepath': filepath_list})\n",
    "    if set_key == \"positive\":\n",
    "        presence_list = list(np.repeat(1, len(filenames)))\n",
    "        filepath_presence_dict.update({'presence': presence_list})\n",
    "    if set_key == \"negative\":\n",
    "        presence_list.extend(list(np.repeat(0, len(filenames))))\n",
    "        filepath_presence_dict.update({'presence': presence_list})       \n",
    "\n",
    "meta_weto = pd.DataFrame(filepath_presence_dict).set_index('filepath')\n",
    "\n",
    "train_df, valid_df = sklearn.model_selection.train_test_split(meta_weto, test_size=0.15, random_state=0)\n",
    "print(f\"created train_df (len {len(train_df)}) and valid_df (len {len(valid_df)})\")\n",
    "print(f\"There are {np.sum(train_df['presence'])} positive samples in train_df\")\n",
    "print(f\"There are {np.sum(train_df['presence']==0)} negative samples in train_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created train_df (len 20) and valid_df (len 10)\n",
      "There are 6 positive samples in train_df\n",
      "There are 14 negative samples in train_df\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df.sample(n=20, axis = 0, random_state=3)\n",
    "valid_df = train_df.sample(n=10, axis = 0, random_state=3)\n",
    "\n",
    "print(f\"created train_df (len {len(train_df)}) and valid_df (len {len(valid_df)})\")\n",
    "print(f\"There are {np.sum(train_df['presence'])} positive samples in train_df\")\n",
    "print(f\"There are {np.sum(train_df['presence']==0)} negative samples in train_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alexnet',\n",
       " 'convnext_base',\n",
       " 'convnext_large',\n",
       " 'convnext_small',\n",
       " 'convnext_tiny',\n",
       " 'densenet121',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'efficientnet_b0',\n",
       " 'efficientnet_b1',\n",
       " 'efficientnet_b2',\n",
       " 'efficientnet_b3',\n",
       " 'efficientnet_b4',\n",
       " 'efficientnet_b5',\n",
       " 'efficientnet_b6',\n",
       " 'efficientnet_b7',\n",
       " 'efficientnet_v2_l',\n",
       " 'efficientnet_v2_m',\n",
       " 'efficientnet_v2_s',\n",
       " 'googlenet',\n",
       " 'inception_v3',\n",
       " 'maxvit_t',\n",
       " 'mnasnet0_5',\n",
       " 'mnasnet0_75',\n",
       " 'mnasnet1_0',\n",
       " 'mnasnet1_3',\n",
       " 'mobilenet_v2',\n",
       " 'mobilenet_v3_large',\n",
       " 'mobilenet_v3_small',\n",
       " 'regnet_x_16gf',\n",
       " 'regnet_x_1_6gf',\n",
       " 'regnet_x_32gf',\n",
       " 'regnet_x_3_2gf',\n",
       " 'regnet_x_400mf',\n",
       " 'regnet_x_800mf',\n",
       " 'regnet_x_8gf',\n",
       " 'regnet_y_128gf',\n",
       " 'regnet_y_16gf',\n",
       " 'regnet_y_1_6gf',\n",
       " 'regnet_y_32gf',\n",
       " 'regnet_y_3_2gf',\n",
       " 'regnet_y_400mf',\n",
       " 'regnet_y_800mf',\n",
       " 'regnet_y_8gf',\n",
       " 'resnet101',\n",
       " 'resnet152',\n",
       " 'resnet18',\n",
       " 'resnet34',\n",
       " 'resnet50',\n",
       " 'resnext101_32x8d',\n",
       " 'resnext101_64x4d',\n",
       " 'resnext50_32x4d',\n",
       " 'shufflenet_v2_x0_5',\n",
       " 'shufflenet_v2_x1_0',\n",
       " 'shufflenet_v2_x1_5',\n",
       " 'shufflenet_v2_x2_0',\n",
       " 'squeezenet1_0',\n",
       " 'squeezenet1_1',\n",
       " 'swin_b',\n",
       " 'swin_s',\n",
       " 'swin_t',\n",
       " 'swin_v2_b',\n",
       " 'swin_v2_s',\n",
       " 'swin_v2_t',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn',\n",
       " 'vit_b_16',\n",
       " 'vit_b_32',\n",
       " 'vit_h_14',\n",
       " 'vit_l_16',\n",
       " 'vit_l_32',\n",
       " 'wide_resnet101_2',\n",
       " 'wide_resnet50_2']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "# List available models\n",
    "all_models = models.list_models()\n",
    "classification_models = models.list_models(module=models)\n",
    "list(classification_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: bcov2mt1\n",
      "Sweep URL: https://wandb.ai/pca_bioacoustics/my-first-sweep/sweeps/bcov2mt1\n"
     ]
    }
   ],
   "source": [
    "# Define sweep config\n",
    "sweep_configuration = {\n",
    "    \"name\": \"sweepdemo\",\n",
    "    \"method\": \"bayes\",\n",
    "    \"metric\": {\"goal\": \"minimize\", \"name\": \"validation_loss\"},\n",
    "    \"parameters\": {\n",
    "        \"learning_rate\": {\"min\": 0.0001, \"max\": 0.1},\n",
    "        \"batch_size\": {\"values\": [64]},\n",
    "        \"epochs\": {\"values\": [2, 5]},\n",
    "        \"optimizer\": {\"values\": [\"adam\", \"sgd\"]},\n",
    "        \"weights\": {\"values\": [None]},\n",
    "        \"architecture\": {\"values\": [\"resnet50\"]},\n",
    "        \"window_samples\": {\"values\": [200]},\n",
    "        \"prob_cutoff\":{\"values\":[0.5]}\n",
    "    },\n",
    "}\n",
    "\n",
    "# Initialize sweep by passing in config.\n",
    "# (Optional) Provide a name of the project.\n",
    "sweep_id = wandb.sweep(sweep=sweep_configuration, project=\"my-first-sweep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Pipeline\n",
    "1. Make the model,\n",
    "2. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "def model_pipeline():\n",
    "\n",
    "  # tell wandb to get started\n",
    "  run = wandb.init(project=\"my-first-sweep\", \n",
    "                  #config=hyperparameters, \n",
    "                  entity='pca_bioacoustics',\n",
    "                  name='sweeper')\n",
    "\n",
    "\n",
    "  # access all HPs through wandb.config, so logging matches execution!\n",
    "  config = wandb.config\n",
    "\n",
    "  # make the model, data, and optimization problem\n",
    "  model, train_loader, test_loader, criterion, optimizer = make(config)\n",
    "\n",
    "  # and use them to train the model\n",
    "  train(model, train_loader, test_loader, criterion, optimizer, config, log_images = False)\n",
    "\n",
    "  # and test its final performance\n",
    "  #test(model, test_loader)\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make(config):\n",
    "    # Make the data\n",
    "    train_data, valid_data = get_data(train=True), get_data(train=False)\n",
    "    train_loader = make_loader(train_data, batch_size=config.batch_size)\n",
    "    test_loader = make_loader(valid_data, batch_size=config.batch_size)\n",
    "\n",
    "    # Make the model\n",
    "    model = get_model(config.batch_size, config.architecture)\n",
    "\n",
    "    # Make the loss and optimizer\n",
    "    #criterion = nn.BCEWithLogitsLoss() #Sigmoid built-in\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=config.learning_rate)\n",
    "    \n",
    "    return model, train_loader, test_loader, criterion, optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define data preprocessors and use dataloader collate function to return PyTorch DataLoader format\n",
    "\n",
    "def get_data(train=True):\n",
    "    preprocessor = SpectrogramPreprocessor(sample_duration=3,height=224,width=224)\n",
    "    preprocessor.pipeline.to_spec.params.window_samples = 200\n",
    "    preprocessor.pipeline.bandpass.bypass=True # Doesn't work with <22k hz samples\n",
    "    if train == True:\n",
    "        dataset = AudioFileDataset(train_df,preprocessor)\n",
    "    if train == False:\n",
    "        dataset = AudioFileDataset(valid_df,preprocessor)\n",
    "        dataset.bypass_augmentations = True # Remove augmentations\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def make_loader(dataset, batch_size):\n",
    "    loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                         batch_size=batch_size, \n",
    "                                         shuffle=True,\n",
    "                                         collate_fn = collate_audio_samples_to_tensors)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(batch_size, architecture):\n",
    "    # Define the model\n",
    "    # No weights - random initialization\n",
    "    model = getattr(models, architecture)(weights=None)\n",
    "\n",
    "    # Replace the last layer (number of classes; sigmoid)\n",
    "    num_features = model.fc.in_features\n",
    "    #model.fc = nn.Linear(num_features, 1) #No need for sigmoid - located in loss func\n",
    "                                          #Binary classifier, therefore output is of length 1\n",
    "    model.fc = nn.Sequential(nn.Linear(in_features=num_features,\n",
    "                                       out_features=1),\n",
    "                             nn.Sigmoid()\n",
    "                             )\n",
    "    # Replace the first and second layers (number of channels and batch size)\n",
    "    model.conv1 = nn.Conv2d(1, batch_size, kernel_size=7, stride=2, padding=3,bias=False)\n",
    "    model.bn1 = nn.BatchNorm2d(batch_size, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    model.to(device)\n",
    "\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define training logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, valid_loader, criterion, optimizer, config, log_images = True):\n",
    "    # tell wandb to watch what the model gets up to: gradients, weights, and more!\n",
    "    wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
    "\n",
    "    #  creating log\n",
    "    log_dict = {\n",
    "        'training_loss_per_batch': [],\n",
    "        'validation_loss_per_batch': [],\n",
    "        'training_accuracy_per_epoch': [],\n",
    "        'validation_accuracy_per_epoch': []\n",
    "    } \n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for epoch in tqdm(range(config.epochs)):\n",
    "        print(f'Epoch {epoch+1}/{config.epochs}')\n",
    "\n",
    "        #  training\n",
    "        print('training...')\n",
    "        train_losses = []\n",
    "        model.train()\n",
    "        for _, (inputs, labels) in enumerate(train_loader):\n",
    "            # Move the data to the device\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            train_loss = criterion(outputs.float(), labels.float())\n",
    "            log_dict['training_loss_per_batch'].append(train_loss.item())\n",
    "            train_losses.append(train_loss.item())\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            # Update the training metrics\n",
    "            print('deriving training accuracy...')\n",
    "            train_acc = accuracy(model, train_loader)\n",
    "            log_dict['training_accuracy_per_epoch'].append(train_acc)\n",
    "            print(f'training accuracy: {train_acc}')\n",
    "\n",
    "\n",
    "\n",
    "        #  validation\n",
    "        print('validating...')\n",
    "        val_losses = []\n",
    "\n",
    "        #Setting network to eval mode\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for _, (inputs, labels) in enumerate(valid_loader):\n",
    "                # Move the data to the device\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Predict\n",
    "                outputs = model(inputs)\n",
    "                val_loss = criterion(outputs.float(), labels.float())\n",
    "                log_dict['validation_loss_per_batch'].append(val_loss.item())\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "            #  computing accuracy\n",
    "            print('deriving validation accuracy...')\n",
    "            val_acc = accuracy(model, valid_loader)\n",
    "            log_dict['validation_accuracy_per_epoch'].append(val_acc)\n",
    "\n",
    "        wandb.log({\"epoch\": epoch,\n",
    "                   \"train_loss\": train_loss,\n",
    "                   \"train_acc\": train_acc,\n",
    "                   \"val_loss\": val_loss,\n",
    "                   \"val_acc\": val_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  defining accuracy function\n",
    "def accuracy(network, dataloader):\n",
    "  network.eval()\n",
    "  total_correct = 0\n",
    "  total_instances = 0\n",
    "  for images, labels in tqdm(dataloader):\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    predictions = torch.argmax(network(images), dim=1)\n",
    "    correct_predictions = sum(predictions==labels).item()\n",
    "    total_correct+=correct_predictions\n",
    "    total_instances+=len(images)\n",
    "  return round(total_correct/total_instances, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try this: https://pytorch.org/torcheval/main/metric_example.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dconfig = dict(\n",
    "    epochs=3,\n",
    "    classes=1,\n",
    "    kernels=[16, 32],\n",
    "    batch_size=64,\n",
    "    learning_rate=0.005,\n",
    "    weights = None,\n",
    "    architecture=\"resnet50\",\n",
    "    window_samples=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: p3znoeck with config:\n",
      "wandb: \tarchitecture: resnet50\n",
      "wandb: \tbatch_size: 64\n",
      "wandb: \tepochs: 2\n",
      "wandb: \tlearning_rate: 0.02127632018351355\n",
      "wandb: \toptimizer: sgd\n",
      "wandb: \tprob_cutoff: 0.5\n",
      "wandb: \tweights: None\n",
      "wandb: \twindow_samples: 200\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "c:\\ProgramData\\Anaconda3\\envs\\amphib_pt\\lib\\site-packages\\wandb\\sdk\\wandb_setup.py:254: ResourceWarning: unclosed file <_io.TextIOWrapper name='c:\\\\Users\\\\gavin hurd\\\\Documents\\\\bioacoustics_local\\\\notebooks_local\\\\wandb\\\\sweep-bcov2mt1\\\\config-p3znoeck.yaml' mode='r' encoding='UTF-8'>\n",
      "  self._sweep_config = config_util.dict_from_config_file(\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep.\n",
      "wandb: WARNING Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\gavin hurd\\Documents\\bioacoustics_local\\notebooks_local\\wandb\\run-20240628_135356-p3znoeck</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pca_bioacoustics/my-first-sweep/runs/p3znoeck' target=\"_blank\">sweeper</a></strong> to <a href='https://wandb.ai/pca_bioacoustics/my-first-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pca_bioacoustics/my-first-sweep/sweeps/bcov2mt1' target=\"_blank\">https://wandb.ai/pca_bioacoustics/my-first-sweep/sweeps/bcov2mt1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pca_bioacoustics/my-first-sweep' target=\"_blank\">https://wandb.ai/pca_bioacoustics/my-first-sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/pca_bioacoustics/my-first-sweep/sweeps/bcov2mt1' target=\"_blank\">https://wandb.ai/pca_bioacoustics/my-first-sweep/sweeps/bcov2mt1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pca_bioacoustics/my-first-sweep/runs/p3znoeck' target=\"_blank\">https://wandb.ai/pca_bioacoustics/my-first-sweep/runs/p3znoeck</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789b68703a8f4926a651ac6794824ac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "training...\n",
      "deriving training accuracy...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0ef78639c64445b9f8335fea5651d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\amphib_pt\\lib\\site-packages\\wandb\\sdk\\lib\\ipython.py:47: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import HTML, display  # type: ignore\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\amphib_pt\\lib\\site-packages\\wandb\\sdk\\lib\\ipython.py:59: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0803afa7295443c3a5b592db752865d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.005 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.226661â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sweeper</strong> at: <a href='https://wandb.ai/pca_bioacoustics/my-first-sweep/runs/p3znoeck' target=\"_blank\">https://wandb.ai/pca_bioacoustics/my-first-sweep/runs/p3znoeck</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240628_135356-p3znoeck\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run p3znoeck errored: RuntimeError('a Tensor with 20 elements cannot be converted to Scalar')\n",
      "wandb: ERROR Run p3znoeck errored: RuntimeError('a Tensor with 20 elements cannot be converted to Scalar')\n",
      "wandb: Agent Starting Run: p01h1s1d with config:\n",
      "wandb: \tarchitecture: resnet50\n",
      "wandb: \tbatch_size: 64\n",
      "wandb: \tepochs: 2\n",
      "wandb: \tlearning_rate: 0.056124006750139586\n",
      "wandb: \toptimizer: adam\n",
      "wandb: \tprob_cutoff: 0.5\n",
      "wandb: \tweights: None\n",
      "wandb: \twindow_samples: 200\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "c:\\ProgramData\\Anaconda3\\envs\\amphib_pt\\lib\\site-packages\\wandb\\sdk\\wandb_setup.py:254: ResourceWarning: unclosed file <_io.TextIOWrapper name='c:\\\\Users\\\\gavin hurd\\\\Documents\\\\bioacoustics_local\\\\notebooks_local\\\\wandb\\\\sweep-bcov2mt1\\\\config-p01h1s1d.yaml' mode='r' encoding='UTF-8'>\n",
      "  self._sweep_config = config_util.dict_from_config_file(\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep.\n",
      "wandb: WARNING Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\gavin hurd\\Documents\\bioacoustics_local\\notebooks_local\\wandb\\run-20240628_135433-p01h1s1d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pca_bioacoustics/my-first-sweep/runs/p01h1s1d' target=\"_blank\">sweeper</a></strong> to <a href='https://wandb.ai/pca_bioacoustics/my-first-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pca_bioacoustics/my-first-sweep/sweeps/bcov2mt1' target=\"_blank\">https://wandb.ai/pca_bioacoustics/my-first-sweep/sweeps/bcov2mt1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pca_bioacoustics/my-first-sweep' target=\"_blank\">https://wandb.ai/pca_bioacoustics/my-first-sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/pca_bioacoustics/my-first-sweep/sweeps/bcov2mt1' target=\"_blank\">https://wandb.ai/pca_bioacoustics/my-first-sweep/sweeps/bcov2mt1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pca_bioacoustics/my-first-sweep/runs/p01h1s1d' target=\"_blank\">https://wandb.ai/pca_bioacoustics/my-first-sweep/runs/p01h1s1d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f0dcb4240b34c7889a3575384701c41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "training...\n",
      "deriving training accuracy...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a3d2ac3a984f51aeb85326b9778432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\envs\\amphib_pt\\lib\\site-packages\\torch\\nn\\modules\\module.py:460: ResourceWarning: unclosed <socket.socket fd=6188, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 50650), raddr=('127.0.0.1', 50649)>\n",
      "  super().__setattr__('_state_dict_pre_hooks', OrderedDict())\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "c:\\ProgramData\\Anaconda3\\envs\\amphib_pt\\lib\\site-packages\\torch\\nn\\modules\\module.py:460: ResourceWarning: unclosed <socket.socket fd=5184, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 50800), raddr=('127.0.0.1', 50799)>\n",
      "  super().__setattr__('_state_dict_pre_hooks', OrderedDict())\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "c:\\ProgramData\\Anaconda3\\envs\\amphib_pt\\lib\\site-packages\\torch\\nn\\modules\\module.py:460: ResourceWarning: unclosed <socket.socket fd=6492, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 50985), raddr=('127.0.0.1', 50984)>\n",
      "  super().__setattr__('_state_dict_pre_hooks', OrderedDict())\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "c:\\ProgramData\\Anaconda3\\envs\\amphib_pt\\lib\\site-packages\\torch\\nn\\modules\\module.py:460: ResourceWarning: unclosed <socket.socket fd=6516, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 51131), raddr=('127.0.0.1', 51130)>\n",
      "  super().__setattr__('_state_dict_pre_hooks', OrderedDict())\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "c:\\ProgramData\\Anaconda3\\envs\\amphib_pt\\lib\\site-packages\\torch\\nn\\modules\\module.py:460: ResourceWarning: unclosed <socket.socket fd=4316, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 51238), raddr=('127.0.0.1', 51237)>\n",
      "  super().__setattr__('_state_dict_pre_hooks', OrderedDict())\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "c:\\ProgramData\\Anaconda3\\envs\\amphib_pt\\lib\\site-packages\\torch\\nn\\modules\\module.py:460: ResourceWarning: unclosed <socket.socket fd=6916, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('127.0.0.1', 51382), raddr=('127.0.0.1', 51381)>\n",
      "  super().__setattr__('_state_dict_pre_hooks', OrderedDict())\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "c:\\ProgramData\\Anaconda3\\envs\\amphib_pt\\lib\\site-packages\\wandb\\sdk\\lib\\ipython.py:47: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import HTML, display  # type: ignore\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Ctrl-C to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sweeper</strong> at: <a href='https://wandb.ai/pca_bioacoustics/my-first-sweep/runs/p01h1s1d' target=\"_blank\">https://wandb.ai/pca_bioacoustics/my-first-sweep/runs/p01h1s1d</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240628_135433-p01h1s1d\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Run p01h1s1d errored: RuntimeError('a Tensor with 20 elements cannot be converted to Scalar')\n",
      "wandb: ERROR Run p01h1s1d errored: RuntimeError('a Tensor with 20 elements cannot be converted to Scalar')\n",
      "wandb: Agent Starting Run: a51b5x7d with config:\n",
      "wandb: \tarchitecture: resnet50\n",
      "wandb: \tbatch_size: 64\n",
      "wandb: \tepochs: 5\n",
      "wandb: \tlearning_rate: 0.01105753168240567\n",
      "wandb: \toptimizer: adam\n",
      "wandb: \tprob_cutoff: 0.5\n",
      "wandb: \tweights: None\n",
      "wandb: \twindow_samples: 200\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "c:\\ProgramData\\Anaconda3\\envs\\amphib_pt\\lib\\site-packages\\wandb\\sdk\\wandb_setup.py:254: ResourceWarning: unclosed file <_io.TextIOWrapper name='c:\\\\Users\\\\gavin hurd\\\\Documents\\\\bioacoustics_local\\\\notebooks_local\\\\wandb\\\\sweep-bcov2mt1\\\\config-a51b5x7d.yaml' mode='r' encoding='UTF-8'>\n",
      "  self._sweep_config = config_util.dict_from_config_file(\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "wandb: WARNING Ignored wandb.init() arg project when running a sweep.\n",
      "wandb: WARNING Ignored wandb.init() arg entity when running a sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\gavin hurd\\Documents\\bioacoustics_local\\notebooks_local\\wandb\\run-20240628_135512-a51b5x7d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pca_bioacoustics/my-first-sweep/runs/a51b5x7d' target=\"_blank\">sweeper</a></strong> to <a href='https://wandb.ai/pca_bioacoustics/my-first-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/pca_bioacoustics/my-first-sweep/sweeps/bcov2mt1' target=\"_blank\">https://wandb.ai/pca_bioacoustics/my-first-sweep/sweeps/bcov2mt1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pca_bioacoustics/my-first-sweep' target=\"_blank\">https://wandb.ai/pca_bioacoustics/my-first-sweep</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/pca_bioacoustics/my-first-sweep/sweeps/bcov2mt1' target=\"_blank\">https://wandb.ai/pca_bioacoustics/my-first-sweep/sweeps/bcov2mt1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pca_bioacoustics/my-first-sweep/runs/a51b5x7d' target=\"_blank\">https://wandb.ai/pca_bioacoustics/my-first-sweep/runs/a51b5x7d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86b85031d00246e2a10d4597e5a3ed7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "training...\n"
     ]
    }
   ],
   "source": [
    "# Build, train and analyze the model with the pipeline\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#model = model_pipeline()\n",
    "wandb.agent(sweep_id, function=model_pipeline) #, count=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amphib_pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
